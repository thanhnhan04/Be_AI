"""
Hu·∫•n luy·ªán m√¥ h√¨nh Implicit ALS (Alternating Least Squares)
Thu·∫≠t to√°n ƒë∆∞·ª£c s·ª≠ d·ª•ng b·ªüi Netflix, Spotify cho Top-N recommendations
T·ªëi ∆∞u cho d·ªØ li·ªáu sparse v√† implicit feedback
"""

import pandas as pd
import numpy as np
import pickle
from pathlib import Path
from datetime import datetime
from scipy.sparse import csr_matrix
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
import logging

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class ImplicitALS:
    """
    Implementation c·ªßa Implicit ALS algorithm
    D·ª±a tr√™n paper "Collaborative Filtering for Implicit Feedback Datasets" (Hu et al., 2008)
    """
    
    def __init__(self, factors=100, regularization=0.01, iterations=15, alpha=40):
        """
        Args:
            factors: S·ªë chi·ªÅu latent factors
            regularization: Lambda cho L2 regularization
            iterations: S·ªë v√≤ng l·∫∑p alternating
            alpha: Confidence scaling parameter
        """
        self.factors = factors
        self.regularization = regularization
        self.iterations = iterations
        self.alpha = alpha
        
        self.user_factors = None
        self.item_factors = None
        
    def fit(self, user_items):
        """
        Hu·∫•n luy·ªán model tr√™n user-item matrix
        
        Args:
            user_items: scipy.sparse matrix (n_users √ó n_items) v·ªõi confidence values
        """
        n_users, n_items = user_items.shape
        
        # Kh·ªüi t·∫°o latent factors v·ªõi gi√° tr·ªã ng·∫´u nhi√™n nh·ªè
        self.user_factors = np.random.normal(0, 0.01, (n_users, self.factors)).astype(np.float32)
        self.item_factors = np.random.normal(0, 0.01, (n_items, self.factors)).astype(np.float32)
        
        logger.info(f"B·∫Øt ƒë·∫ßu training ALS: {n_users} users, {n_items} items")
        logger.info(f"Factors={self.factors}, Regularization={self.regularization}, Iterations={self.iterations}")
        
        # Convert sang CSR format cho efficient row access
        Cui = user_items.tocsr().astype(np.float32)
        Ciu = user_items.T.tocsr().astype(np.float32)
        
        # Alternating Least Squares
        for iteration in range(self.iterations):
            # Fix item factors, solve cho user factors
            self._least_squares(Cui, self.user_factors, self.item_factors)
            
            # Fix user factors, solve cho item factors
            self._least_squares(Ciu, self.item_factors, self.user_factors)
            
            if (iteration + 1) % 5 == 0:
                logger.info(f"  Iteration {iteration + 1}/{self.iterations}")
        
        logger.info("‚úì Training ho√†n t·∫•t")
        
    def _least_squares(self, Cui, X, Y):
        """
        Solve least squares cho m·ªôt b√™n (user ho·∫∑c item)
        
        Args:
            Cui: Confidence matrix (n √ó m)
            X: Factors c·∫ßn update (n √ó factors)
            Y: Factors c·ªë ƒë·ªãnh (m √ó factors)
        """
        n_users = X.shape[0]
        YtY = Y.T.dot(Y)  # Pre-compute Y^T * Y
        
        for u in range(n_users):
            # L·∫•y items m√† user u ƒë√£ t∆∞∆°ng t√°c
            items = Cui[u].indices
            if len(items) == 0:
                continue
                
            # Confidence values
            Cu = Cui[u].data
            
            # Preference (binary: 1 n·∫øu c√≥ t∆∞∆°ng t√°c)
            Pu = np.ones(len(items), dtype=np.float32)
            
            # Y_u: ch·ªâ l·∫•y item factors c·ªßa items ƒë√£ t∆∞∆°ng t√°c
            Y_u = Y[items]
            
            # Solve: (Y^T * C_u * Y + lambda * I) * x_u = Y^T * C_u * p_u
            # V·ªõi C_u l√† diagonal matrix v·ªõi Cu values
            
            # A = Y^T * Y + lambda * I
            A = YtY + self.regularization * np.eye(self.factors, dtype=np.float32)
            
            # C·ªông th√™m (Cu - 1) * Y_i * Y_i^T cho m·ªói item i user ƒë√£ t∆∞∆°ng t√°c
            for i, confidence in enumerate(Cu):
                A += (confidence - 1) * np.outer(Y_u[i], Y_u[i])
            
            # b = Y^T * C_u * p_u = sum(Cu_i * Y_i)
            b = Y_u.T.dot(Cu * Pu)
            
            # Solve Ax = b
            X[u] = np.linalg.solve(A, b)
    
    def recommend(self, user_idx, user_items_row, N=2, filter_already_liked_items=True):
        """
        T·∫°o top-N recommendations cho user
        
        Args:
            user_idx: Index c·ªßa user
            user_items_row: Row t·ª´ user-item matrix (ƒë·ªÉ l·ªçc items ƒë√£ xem)
            N: S·ªë l∆∞·ª£ng recommendations
            filter_already_liked_items: C√≥ l·ªçc items ƒë√£ t∆∞∆°ng t√°c kh√¥ng
            
        Returns:
            (item_indices, scores): Arrays c·ªßa item indices v√† scores
        """
        # T√≠nh scores cho t·∫•t c·∫£ items
        scores = self.user_factors[user_idx].dot(self.item_factors.T)
        # L·ªçc items ƒë√£ xem n·∫øu c·∫ßn
        if filter_already_liked_items:
            liked_items = user_items_row.indices
            scores[liked_items] = -np.inf
        # L·∫•y top-N (kh√¥ng v∆∞·ª£t qu√° s·ªë l∆∞·ª£ng item)
        N = min(N, len(scores))
        if N == 0:
            return [], []
        top_items = np.argpartition(scores, -N)[-N:]
        top_items = top_items[np.argsort(-scores[top_items])]
        return top_items, scores[top_items]


def calculate_metrics(model, train_user_items, test_user_items, user_items_matrix, K=10):
    """
    T√≠nh c√°c metrics: Precision@K, Recall@K, NDCG@K, Hit Rate@K
    
    Args:
        model: Trained ALS model
        train_user_items: Dict {user_idx: set(item_idx)} t·ª´ train set
        test_user_items: Dict {user_idx: set(item_idx)} t·ª´ test set (ch·ªâ items relevant)
        user_items_matrix: Sparse matrix (users √ó items)
        K: Top-K recommendations
    """
    precisions = []
    recalls = []
    ndcgs = []
    hits = []
    
    # Ch·ªâ ƒë√°nh gi√° users c√≥ items trong test set
    test_users = list(test_user_items.keys())
    
    for user_idx in test_users:
        # L·∫•y items ƒë√£ t∆∞∆°ng t√°c trong train ƒë·ªÉ lo·∫°i tr·ª´
        train_items = train_user_items.get(user_idx, set())
        
        # L·∫•y top-K recommendations (ALS t·ª± ƒë·ªông lo·∫°i tr·ª´ items ƒë√£ c√≥ trong ma tr·∫≠n)
        # recommend() tr·∫£ v·ªÅ (item_ids, scores)
        recommended_items, scores = model.recommend(
            user_idx, 
            user_items_matrix[user_idx],
            N=K,
            filter_already_liked_items=True
        )
        
        # Items th·ª±c s·ª± relevant trong test set
        relevant_items = test_user_items[user_idx]
        
        # T√≠nh s·ªë l∆∞·ª£ng hits
        recommended_set = set(recommended_items)
            # L·∫•y top-N (kh√¥ng v∆∞·ª£t qu√° s·ªë l∆∞·ª£ng item)
        N = min(N, len(scores))
        if N == 0:
            return [], []
            top_items = np.argpartition(scores, -N)[-N:]
            top_items = top_items[np.argsort(-scores[top_items])]
            return top_items, scores[top_items]
        precisions.append(precision)
        
        # Recall@K
        recall = hits_count / len(relevant_items) if len(relevant_items) > 0 else 0
        recalls.append(recall)
        
        # NDCG@K
        dcg = 0.0
        for i, item_idx in enumerate(recommended_items):
            if item_idx in relevant_items:
                dcg += 1.0 / np.log2(i + 2)
        
        idcg = sum(1.0 / np.log2(i + 2) for i in range(min(len(relevant_items), K)))
        ndcg = dcg / idcg if idcg > 0 else 0
        ndcgs.append(ndcg)
        
        # Hit Rate@K
        has_hit = 1 if hits_count > 0 else 0
        hits.append(has_hit)
    
    return {
        'precision': np.mean(precisions),
        'recall': np.mean(recalls),
        'ndcg': np.mean(ndcgs),
        'hit_rate': np.mean(hits)
    }


def main():
    """Pipeline hu·∫•n luy·ªán Implicit ALS"""
    
    logger.info("=" * 80)
    logger.info("IMPLICIT ALS TRAINING PIPELINE - TOP-N RECOMMENDATIONS")
    logger.info("=" * 80)
    
    # ƒê∆∞·ªùng d·∫´n
    script_dir = Path(__file__).resolve().parent
    data_dir = script_dir.parent / "data"
    model_dir = script_dir.parent / "models"
    model_dir.mkdir(exist_ok=True)
    
    # ========== B∆Ø·ªöC 1: Load v√† l·ªçc d·ªØ li·ªáu ========== 
    logger.info("\nüìä B∆Ø·ªöC 1: Load v√† l·ªçc d·ªØ li·ªáu")
    
    df = pd.read_csv(data_dir / "processed_interactions.csv")
    logger.info(f"T·ªïng s·ªë t∆∞∆°ng t√°c (th√¥): {len(df)}")
    
    # ƒê·ªïi t√™n c·ªôt
    df = df.rename(columns={'experience_id': 'item_id', 'rating': 'rating'})
    
    # L·ªçc d·ªØ li·ªáu - gi·ªØ active users v√† popular items
    MIN_USER_INTERACTIONS = 1
    MIN_ITEM_INTERACTIONS = 1
    
    logger.info(f"L·ªçc: Min user interactions={MIN_USER_INTERACTIONS}, Min item interactions={MIN_ITEM_INTERACTIONS}")
    
    iteration = 0
    prev_len = len(df)
    
    while True:
        iteration += 1
        user_counts = df['user_id'].value_counts()
        item_counts = df['item_id'].value_counts()
        
        valid_users = user_counts[user_counts >= MIN_USER_INTERACTIONS].index
        valid_items = item_counts[item_counts >= MIN_ITEM_INTERACTIONS].index
        
        df = df[df['user_id'].isin(valid_users) & df['item_id'].isin(valid_items)]
        
        if len(df) == prev_len:
            break
        prev_len = len(df)
    
    logger.info(f"‚úì L·ªçc ho√†n t·∫•t sau {iteration} v√≤ng l·∫∑p")
    logger.info(f"  - T∆∞∆°ng t√°c: {len(df)} (gi·ªØ {len(df)/252361*100:.1f}%)")
    logger.info(f"  - Users: {df['user_id'].nunique()}")
    logger.info(f"  - Items: {df['item_id'].nunique()}")
    logger.info(f"  - M·∫≠t ƒë·ªô: {len(df)/(df['user_id'].nunique()*df['item_id'].nunique())*100:.3f}%")
    
    # ========== B∆Ø·ªöC 2: Chuy·ªÉn sang Implicit Feedback ========== 
    logger.info("\nüîÑ B∆Ø·ªöC 2: Chuy·ªÉn ƒë·ªïi sang Implicit Feedback")
    
    # CHI·∫æN L∆Ø·ª¢C: Rating ‚â• 4 = 1 (positive feedback), ng∆∞·ª£c l·∫°i = 0
    # Sau ƒë√≥ apply confidence weighting
    RATING_THRESHOLD = 4.0
    
    # T·∫°o binary feedback
    df['implicit_feedback'] = (df['rating'] >= RATING_THRESHOLD).astype(int)
    
    # Confidence weighting: confidence = 1 + alpha * rating
    # Alpha cao h∆°n = tin t∆∞·ªüng rating cao h∆°n
    ALPHA = 10
    df['confidence'] = 1 + ALPHA * df['rating']
    
    logger.info(f"Ng∆∞·ª°ng rating: ‚â•{RATING_THRESHOLD} sao = positive feedback")
    logger.info(f"Alpha (confidence weight): {ALPHA}")
    logger.info(f"Positive feedback: {df['implicit_feedback'].sum()} / {len(df)} ({df['implicit_feedback'].mean()*100:.1f}%)")
    
    # ========== B∆Ø·ªöC 3: Train/Test Split ========== 
    logger.info("\n‚úÇÔ∏è B∆Ø·ªöC 3: Chia Train/Test")
    
    # Split theo th·ªùi gian ho·∫∑c random
    train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)
    
    logger.info(f"Train: {len(train_df)} t∆∞∆°ng t√°c")
    logger.info(f"Test: {len(test_df)} t∆∞∆°ng t√°c")
    
    # ========== B∆Ø·ªöC 4: Label Encoding ========== 
    logger.info("\nüè∑Ô∏è B∆Ø·ªöC 4: M√£ h√≥a nh√£n")
    
    user_encoder = LabelEncoder()
    item_encoder = LabelEncoder()
    
    all_users = pd.concat([train_df['user_id'], test_df['user_id']]).unique()
    all_items = pd.concat([train_df['item_id'], test_df['item_id']]).unique()
    
    user_encoder.fit(all_users)
    item_encoder.fit(all_items)
    
    train_df['user_idx'] = user_encoder.transform(train_df['user_id'])
    train_df['item_idx'] = item_encoder.transform(train_df['item_id'])
    
    test_df['user_idx'] = user_encoder.transform(test_df['user_id'])
    test_df['item_idx'] = item_encoder.transform(test_df['item_id'])
    
    logger.info(f"‚úì ƒê√£ m√£ h√≥a {len(user_encoder.classes_)} users, {len(item_encoder.classes_)} items")
    
    # L∆∞u encoders
    encoder_path = model_dir / "encoders_als.pkl"
    with open(encoder_path, 'wb') as f:
        pickle.dump({
            'user_encoder': user_encoder,
            'item_encoder': item_encoder
        }, f)
    logger.info(f"‚úì Encoders ƒë√£ l∆∞u: {encoder_path}")
    
    # ========== B∆Ø·ªöC 5: T·∫°o Sparse Matrix ========== 
    logger.info("\nüî¢ B∆Ø·ªöC 5: T·∫°o User-Item Sparse Matrix")
    
    n_users = len(user_encoder.classes_)
    n_items = len(item_encoder.classes_)
    
    # T·∫°o ma tr·∫≠n t·ª´ train data v·ªõi confidence values
    user_items_matrix = csr_matrix(
        (train_df['confidence'].values, (train_df['user_idx'].values, train_df['item_idx'].values)),
        shape=(n_users, n_items),
        dtype=np.float32
    )
    
    logger.info(f"Ma tr·∫≠n shape: {user_items_matrix.shape}")
    logger.info(f"Non-zero entries: {user_items_matrix.nnz}")
    logger.info(f"Sparsity: {(1 - user_items_matrix.nnz / (n_users * n_items)) * 100:.2f}%")
    
    # ========== B∆Ø·ªöC 6: Train ALS Model ========== 
    logger.info("\nüß† B∆Ø·ªöC 6: Hu·∫•n luy·ªán Implicit ALS Model")
    
    # Hyperparameters t·ªëi ∆∞u cho ALS
    model = ImplicitALS(
        factors=100,              # S·ªë chi·ªÅu latent factors
        regularization=0.05,      # L2 regularization
        iterations=15,            # S·ªë v√≤ng l·∫∑p alternating
        alpha=ALPHA               # Confidence scaling
    )
    
    logger.info(f"C·∫•u h√¨nh ALS:")
    logger.info(f"  - Factors: {model.factors}")
    logger.info(f"  - Regularization: {model.regularization}")
    logger.info(f"  - Iterations: {model.iterations}")
    logger.info(f"  - Alpha: {ALPHA}")
    
    # Train model
    logger.info("\nB·∫Øt ƒë·∫ßu training...")
    model.fit(user_items_matrix)
    
    logger.info("‚úì Training ho√†n t·∫•t!")
    
    # ========== B∆Ø·ªöC 7: ƒê√°nh gi√° Model ========== 
    logger.info("\nüìà B∆Ø·ªöC 7: ƒê√°nh gi√° hi·ªáu nƒÉng Model")
    
    # Chu·∫©n b·ªã d·ªØ li·ªáu cho evaluation
    # Train user-items (ƒë·ªÉ lo·∫°i tr·ª´ kh·ªèi recommendations)
    train_user_items = train_df.groupby('user_idx')['item_idx'].apply(set).to_dict()
    
    # Test user-items (ch·ªâ l·∫•y positive feedback)
    test_positive = test_df[test_df['implicit_feedback'] == 1]
    test_user_items = test_positive.groupby('user_idx')['item_idx'].apply(set).to_dict()
    
    logger.info(f"Test users v·ªõi positive feedback: {len(test_user_items)}")
    logger.info(f"T·ªïng positive interactions trong test: {len(test_positive)}")
    
    # T√≠nh metrics cho K = 5, 10, 20
    logger.info("\nüìä K·∫øt qu·∫£ Evaluation:")
    all_metrics = {}
    
    for K in [5, 10, 20]:
        logger.info(f"\nƒêang ƒë√°nh gi√° @{K}...")
        metrics = calculate_metrics(
            model, 
            train_user_items, 
            test_user_items, 
            user_items_matrix,
            K=K
        )
        
        all_metrics[f'precision@{K}'] = metrics['precision']
        all_metrics[f'recall@{K}'] = metrics['recall']
        all_metrics[f'ndcg@{K}'] = metrics['ndcg']
        all_metrics[f'hit_rate@{K}'] = metrics['hit_rate']
        
        logger.info(f"  Precision@{K}: {metrics['precision']:.4f} ({metrics['precision']*100:.2f}%)")
        logger.info(f"  Recall@{K}: {metrics['recall']:.4f} ({metrics['recall']*100:.2f}%)")
        logger.info(f"  NDCG@{K}: {metrics['ndcg']:.4f}")
        logger.info(f"  Hit Rate@{K}: {metrics['hit_rate']:.4f} ({metrics['hit_rate']*100:.2f}%)")
    
    # ========== B∆Ø·ªöC 8: L∆∞u Model ========== 
    logger.info("\nüíæ B∆Ø·ªöC 8: L∆∞u Model")
    
    # L∆∞u model (ch·ªâ l∆∞u factors, kh√¥ng l∆∞u object ƒë·ªÉ tr√°nh pickle issues)
    model_path = model_dir / "als_model.pkl"
    with open(model_path, 'wb') as f:
        pickle.dump({
            'user_factors': model.user_factors,
            'item_factors': model.item_factors
        }, f)
    logger.info(f"‚úì Model ƒë√£ l∆∞u: {model_path}")
    
    # L∆∞u metadata
    metadata_path = model_dir / "als_metadata.json"
    metadata = {
        'trained_at': datetime.now().isoformat(),
        'algorithm': 'Implicit ALS',
        'n_users': n_users,
        'n_items': n_items,
        'n_train_interactions': len(train_df),
        'n_test_interactions': len(test_df),
        'factors': model.factors,
        'regularization': model.regularization,
        'iterations': model.iterations,
        'alpha': ALPHA,
        'rating_threshold': RATING_THRESHOLD,
        'metrics': all_metrics
    }
    
    import json
    with open(metadata_path, 'w') as f:
        json.dump(metadata, f, indent=2)
    logger.info(f"‚úì Metadata ƒë√£ l∆∞u: {metadata_path}")
    
    # ========== T√≥m t·∫Øt ========== 
    logger.info("\n" + "=" * 80)
    logger.info("‚úÖ IMPLICIT ALS TRAINING HO√ÄN T·∫§T")
    logger.info("=" * 80)
    logger.info("\nüìÅ C√°c file ƒë√£ t·∫°o:")
    logger.info(f"  - {model_path}")
    logger.info(f"  - {encoder_path}")
    logger.info(f"  - {metadata_path}")
    
    logger.info("\nüìä Hi·ªáu nƒÉng Model:")
    for k, v in all_metrics.items():
        logger.info(f"  {k}: {v:.4f} ({v*100:.2f}%)")
    
    logger.info("=" * 80)
    
    return model, user_encoder, item_encoder, all_metrics


if __name__ == "__main__":
    model, user_enc, item_enc, metrics = main()
    
    # ========== V√ç D·ª§: L·∫•y g·ª£i √Ω cho user ========== 
    print("\n" + "="*80)
    print("V√ç D·ª§: Top 10 g·ª£i √Ω cho m·ªôt user m·∫´u")
    print("="*80)
    
    try:
        # L·∫•y user ƒë·∫ßu ti√™n t·ª´ encoder
        sample_user_id = user_enc.classes_[0]
        user_idx = user_enc.transform([sample_user_id])[0]
        
        # Load l·∫°i d·ªØ li·ªáu ƒë√£ l·ªçc (ch·ªâ users/items trong encoder)
        script_dir = Path(__file__).resolve().parent
        data_dir = script_dir.parent / "data"
        df = pd.read_csv(data_dir / "processed_ratings.csv")
        df = df.rename(columns={'business_id': 'item_id', 'stars': 'rating'})
        
        # L·ªçc ch·ªâ gi·ªØ users v√† items c√≥ trong encoder
        valid_users = set(user_enc.classes_)
        valid_items = set(item_enc.classes_)
        df = df[df['user_id'].isin(valid_users) & df['item_id'].isin(valid_items)]
        
        # Transform
        df['user_idx'] = user_enc.transform(df['user_id'])
        df['item_idx'] = item_enc.transform(df['item_id'])
        df['confidence'] = 1 + 10 * df['rating']
        
        n_users = len(user_enc.classes_)
        n_items = len(item_enc.classes_)
        
        user_items_matrix = csr_matrix(
            (df['confidence'].values, (df['user_idx'].values, df['item_idx'].values)),
            shape=(n_users, n_items),
            dtype=np.float32
        )
        
        # L·∫•y recommendations
        recommended_items, scores = model.recommend(
            user_idx, 
            user_items_matrix[user_idx],
            N=10,
            filter_already_liked_items=True
        )
        
        print(f"\nTop 10 g·ª£i √Ω cho user {sample_user_id}:")
        for rank, (item_idx, score) in enumerate(zip(recommended_items, scores), 1):
            item_id = item_enc.inverse_transform([item_idx])[0]
            print(f"  {rank}. Item ID: {item_id} (confidence score: {score:.3f})")
            
    except Exception as e:
        print(f"L·ªói: {e}")
        import traceback
        traceback.print_exc()
        
        print(f"\nTop 10 g·ª£i √Ω cho user {sample_user_id}:")
        for rank, (item_idx, score) in enumerate(zip(recommended_items, scores), 1):
            item_id = item_enc.inverse_transform([item_idx])[0]
            print(f"  {rank}. Experience ID: {item_id} (confidence score: {score:.3f})")
            
    except Exception as e:
        print(f"L·ªói: {e}")
        import traceback
        traceback.print_exc()
